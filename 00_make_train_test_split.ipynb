{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urtpDwKN6gc2",
        "outputId": "3076c85e-2afe-4556-fa20-50385a71e7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1w0De0D9R8aQ55ifKg_V1CmW_CVuuVATr\n",
            "From (redirected): https://drive.google.com/uc?id=1w0De0D9R8aQ55ifKg_V1CmW_CVuuVATr&confirm=t&uuid=5c9b9d3b-068e-4e76-9d5a-e13501cda66b\n",
            "To: /content/workspace.zip\n",
            "100% 195M/195M [00:02<00:00, 71.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Download the file from Google Drive\n",
        "!gdown --id 1w0De0D9R8aQ55ifKg_V1CmW_CVuuVATr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/workspace.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqlj9-Lp60Ey",
        "outputId": "c953f4d5-b3f9-413e-d4de-fda133e8a323"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/workspace.zip\n",
            "   creating: workspace/\n",
            "  inflating: workspace/users.parquet  \n",
            "  inflating: workspace/X_all.npy     \n",
            "  inflating: workspace/X_emb.npy     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================================\n",
        "# 00_make_train_test_split.ipynb\n",
        "# Author: Debjit\n",
        "#\n",
        "# Goal:\n",
        "#   Create a single, shared train/test split for all models.\n",
        "#   This script:\n",
        "#     - Loads X_all.npy and users.parquet\n",
        "#     - Creates train/test indices with a fixed random_state\n",
        "#     - Saves indices and optional split files into /content/workspace\n",
        "#\n",
        "# After running this, all teammates should reuse train_idx.npy/test_idx.npy.\n",
        "# ======================================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- CONFIG: adjust if your path is slightly different ----------------\n",
        "WORKSPACE_DIR = Path(\"/content/workspace\")   # or Path(\"workspace\") if you're in project root\n",
        "\n",
        "X_ALL_PATH = WORKSPACE_DIR / \"X_all.npy\"\n",
        "USERS_PATH = WORKSPACE_DIR / \"users.parquet\"\n",
        "\n",
        "print(\"Loading data from:\")\n",
        "print(\"  \", X_ALL_PATH)\n",
        "print(\"  \", USERS_PATH)\n",
        "\n",
        "X_all = np.load(X_ALL_PATH)          # shape: (n_users, n_features)\n",
        "users = pd.read_parquet(USERS_PATH)  # columns: user_id, ...\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"  X_all :\", X_all.shape)\n",
        "print(\"  users :\", users.shape)\n",
        "\n",
        "n_users = X_all.shape[0]\n",
        "assert n_users == len(users), \"X_all and users row count must match!\"\n",
        "\n",
        "# --- Create index array ------------------------------------------------\n",
        "all_idx = np.arange(n_users)\n",
        "\n",
        "# IMPORTANT: fixed random_state so split is reproducible for everyone\n",
        "TRAIN_SIZE = 0.8   # 80% train, 20% test (change if you want)\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "train_idx, test_idx = train_test_split(\n",
        "    all_idx,\n",
        "    train_size=TRAIN_SIZE,\n",
        "    random_state=RANDOM_STATE,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain size: {len(train_idx)}\")\n",
        "print(f\"Test size : {len(test_idx)}\")\n",
        "\n",
        "# --- Save indices so everyone can reuse them ---------------------------\n",
        "TRAIN_IDX_PATH = WORKSPACE_DIR / \"train_idx.npy\"\n",
        "TEST_IDX_PATH  = WORKSPACE_DIR / \"test_idx.npy\"\n",
        "\n",
        "np.save(TRAIN_IDX_PATH, train_idx)\n",
        "np.save(TEST_IDX_PATH, test_idx)\n",
        "\n",
        "print(f\"\\nSaved index files:\")\n",
        "print(\"  \", TRAIN_IDX_PATH)\n",
        "print(\"  \", TEST_IDX_PATH)\n",
        "\n",
        "# --- (Optional) also save split X_all and users ------------------------\n",
        "X_all_train = X_all[train_idx]\n",
        "X_all_test  = X_all[test_idx]\n",
        "\n",
        "users_train = users.iloc[train_idx].reset_index(drop=True)\n",
        "users_test  = users.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "X_ALL_TRAIN_PATH = WORKSPACE_DIR / \"X_all_train.npy\"\n",
        "X_ALL_TEST_PATH  = WORKSPACE_DIR / \"X_all_test.npy\"\n",
        "USERS_TRAIN_PATH = WORKSPACE_DIR / \"users_train.parquet\"\n",
        "USERS_TEST_PATH  = WORKSPACE_DIR / \"users_test.parquet\"\n",
        "\n",
        "np.save(X_ALL_TRAIN_PATH, X_all_train)\n",
        "np.save(X_ALL_TEST_PATH, X_all_test)\n",
        "users_train.to_parquet(USERS_TRAIN_PATH, index=False)\n",
        "users_test.to_parquet(USERS_TEST_PATH, index=False)\n",
        "\n",
        "print(\"\\nAlso saved split data:\")\n",
        "print(\"  \", X_ALL_TRAIN_PATH)\n",
        "print(\"  \", X_ALL_TEST_PATH)\n",
        "print(\"  \", USERS_TRAIN_PATH)\n",
        "print(\"  \", USERS_TEST_PATH)\n",
        "\n",
        "print(\"\\n Global train/test split created. Share these files with your team.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk6E7h4Y66u5",
        "outputId": "9513286e-9d0f-451f-e030-05ac46176704"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from:\n",
            "   /content/workspace/X_all.npy\n",
            "   /content/workspace/users.parquet\n",
            "Shapes:\n",
            "  X_all : (206207, 132)\n",
            "  users : (206207, 1)\n",
            "\n",
            "Train size: 164965\n",
            "Test size : 41242\n",
            "\n",
            "Saved index files:\n",
            "   /content/workspace/train_idx.npy\n",
            "   /content/workspace/test_idx.npy\n",
            "\n",
            "Also saved split data:\n",
            "   /content/workspace/X_all_train.npy\n",
            "   /content/workspace/X_all_test.npy\n",
            "   /content/workspace/users_train.parquet\n",
            "   /content/workspace/users_test.parquet\n",
            "\n",
            " Global train/test split created. Share these files with your team.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "WORKSPACE_DIR = Path(\"/content/workspace\")\n",
        "\n",
        "X_all = np.load(WORKSPACE_DIR / \"X_all.npy\")\n",
        "users = pd.read_parquet(WORKSPACE_DIR / \"users.parquet\")\n",
        "\n",
        "train_idx = np.load(WORKSPACE_DIR / \"train_idx.npy\")\n",
        "test_idx  = np.load(WORKSPACE_DIR / \"test_idx.npy\")\n",
        "\n",
        "X_train = X_all[train_idx]\n",
        "X_test  = X_all[test_idx]\n",
        "\n",
        "# optional: users_train/users_test if needed\n",
        "users_train = users.iloc[train_idx].reset_index(drop=True)\n",
        "users_test  = users.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "print(X_train.shape, X_test.shape, users_train.shape, users_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS6_0zBM7G42",
        "outputId": "f7c4ad4d-61cf-4607-e092-83539351803c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(164965, 132) (41242, 132) (164965, 1) (41242, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r workspace_updated.zip workspace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io4CTde-7XEd",
        "outputId": "218b7e76-2f5b-4db9-8582-af80cf3d87d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: workspace/ (stored 0%)\n",
            "  adding: workspace/train_idx.npy (deflated 62%)\n",
            "  adding: workspace/X_emb.npy (deflated 9%)\n",
            "  adding: workspace/users_train.parquet (deflated 19%)\n",
            "  adding: workspace/users.parquet (deflated 75%)\n",
            "  adding: workspace/X_all.npy (deflated 10%)\n",
            "  adding: workspace/test_idx.npy (deflated 62%)\n",
            "  adding: workspace/users_test.parquet (deflated 19%)\n",
            "  adding: workspace/X_all_train.npy (deflated 7%)\n",
            "  adding: workspace/X_all_test.npy (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WL768NPm73BN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}